{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed71500f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"convert.py\", line 10, in <module>\n",
      "    import pycocotools.mask as mask_util\n",
      "ModuleNotFoundError: No module named 'pycocotools'\n"
     ]
    }
   ],
   "source": [
    "!python convert.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ffceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load convert.py\n",
    "import os\n",
    "import cv2\n",
    "import pathlib\n",
    "import argparse\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pycocotools.mask as mask_util\n",
    "\n",
    "from random import randint\n",
    "from tqdm import tqdm\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "\n",
    "def get_config():\n",
    "    parser = argparse.ArgumentParser(description='Extract Segmentation Mask.')\n",
    "\n",
    "    parser.add_argument('coco_folder', type=pathlib.Path)\n",
    "    parser.add_argument('--data_type', type=str, choices=['train', 'val'],\n",
    "                        help='select whether the data you want to convert is train or val.')\n",
    "    parser.add_argument(\"--save_root\", type=pathlib.Path)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def get_annotation_filename(data_type: str) -> str:\n",
    "    \n",
    "    if data_type == \"train\":\n",
    "        json_name = 'densepose_coco_2014_train.json'\n",
    "\n",
    "    elif data_type == \"val\":\n",
    "        json_name = 'densepose_coco_2014_minival.json'\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('you must input \"train\" or \"val\".')\n",
    "\n",
    "    return json_name\n",
    "\n",
    "\n",
    "def GetDensePoseMask(Polys):\n",
    "    MaskGen = np.zeros([256,256])\n",
    "    for i in range(1,15):\n",
    "        if(Polys[i-1]):\n",
    "            current_mask = mask_util.decode(Polys[i-1])\n",
    "            MaskGen[current_mask>0] = i\n",
    "    return MaskGen\n",
    "\n",
    "\n",
    "def make_mask(coco: COCO, img_ids: list, img_folder_name: str) -> None:\n",
    "\n",
    "    for img_id in tqdm(img_ids):\n",
    "\n",
    "        # Load the image\n",
    "        im = coco.loadImgs(img_id)[0]  \n",
    "\n",
    "        # Load Anns for the selected image.\n",
    "        ann_ids = coco.getAnnIds( imgIds=im['id'] )\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "        # Now read and b\n",
    "        img_name = args.coco_folder / img_folder_name / im['file_name']\n",
    "        cur_image=cv2.imread(str(img_name))\n",
    "\n",
    "        # I_vis = cur_image.copy()\n",
    "        result_mask = np.zeros(cur_image.shape[:2])\n",
    "\n",
    "        for ann in anns:  \n",
    "            bbr =  np.array(ann['bbox']).astype(int) # the box.\n",
    "            if( 'dp_masks' in ann.keys()): # If we have densepose annotation for this ann, \n",
    "                bbox_mask = GetDensePoseMask(ann['dp_masks'])\n",
    "\n",
    "                x1,y1,x2,y2 = bbr[0],bbr[1],bbr[0]+bbr[2],bbr[1]+bbr[3]\n",
    "                x2 = min( [ x2, cur_image.shape[1] ] );  y2 = min( [ y2, cur_image.shape[0] ] )\n",
    "\n",
    "                mask_img = cv2.resize( bbox_mask, (int(x2-x1),int(y2-y1)) ,interpolation=cv2.INTER_NEAREST)\n",
    "                # MaskBool = np.tile((mask_img==0)[:,:,np.newaxis],[1,1,3])\n",
    "\n",
    "                result_mask[y1:y2,x1:x2] = mask_img\n",
    "\n",
    "        save_name = pathlib.Path(im['file_name'])\n",
    "        save_name = save_name.stem + '.png'\n",
    "        save_path = args.save_root / save_name\n",
    "        cv2.imwrite(str(save_path), result_mask)\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    args = get_config()\n",
    "    args.save_root.mkdir(exist_ok=True)\n",
    "\n",
    "    json_filename = get_annotation_filename(args.data_type)\n",
    "    coco = COCO(args.coco_folder / json_filename) \n",
    "\n",
    "    # Get img id's for the minival dataset.\n",
    "    im_ids = coco.getImgIds()\n",
    "\n",
    "    img_folder_name = args.data_type + \"2014\"\n",
    "    make_mask(coco, im_ids, img_folder_name)\n",
    "    \n",
    "\n",
    "\n",
    "#  A  A\n",
    "# (‘ㅅ‘=)\n",
    "# J.M.Seo\n",
    "# From Alchera Inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61286c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python img_processing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0cab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load img_processing.py\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import glob\n",
    "import math\n",
    "\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR,borderMode=cv2.BORDER_CONSTANT,borderValue=(0,0,0))\n",
    "    return result\n",
    "\n",
    "def contrast_roi(img, low, high):\n",
    "    h, w = img.shape\n",
    "    img_ = np.zeros(img.shape, dtype=np.uint8)\n",
    "\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            temp = int((255 / (high - low)) * (img[y][x] - low))\n",
    "            if temp > 255:\n",
    "                img_[y][x] = 255\n",
    "            elif temp < 0:\n",
    "                img_[y][x] = 0\n",
    "            else:\n",
    "                img_[y][x] = temp\n",
    "\n",
    "    return img_\n",
    "\n",
    "\n",
    "def filter_roi_carpal_and_joint(roi):\n",
    "    img = roi.copy()\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    ###이진화\n",
    "    # 마스크 생성을 위해, 밝기 강조한 Lab으로 이미지 변환\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)\n",
    "\n",
    "    # 모폴로지\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (50, 50))\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, k)\n",
    "\n",
    "    # 블러\n",
    "    img = cv2.GaussianBlur(img, (15, 15), 0)\n",
    "\n",
    "    # threshold 적용을 위해 Lab에서 Grayscale로 이미지 변환\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_Lab2BGR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 이진화\n",
    "    ret, mask = cv2.threshold(img, np.mean(img), 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # 컨투어\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(mask, contours, -1, (255, 255, 255), -1)\n",
    "\n",
    "    ###강조\n",
    "    img = roi.copy()\n",
    "\n",
    "    # 모폴로지\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (50, 50))\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, k)\n",
    "\n",
    "    # contrast\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if img.mean() <= 15:\n",
    "        low = img.mean() * 1.5\n",
    "        high = img.mean() * 1.6\n",
    "    elif img.mean() <= 20:\n",
    "        low = img.mean() * 1.5\n",
    "        high = img.mean() * 1.8\n",
    "    else:\n",
    "        low = img.mean() * 1.5\n",
    "        high = img.mean() * 2\n",
    "\n",
    "    img = contrast_roi(img, low, high)\n",
    "\n",
    "    # 컨투어\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(img, contours, -1, (255, 255, 255), -1)\n",
    "\n",
    "    # 마스크랑 비트 연산\n",
    "    img = cv2.bitwise_and(img, mask)\n",
    "\n",
    "    # 크기 표준화\n",
    "    img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def filter_roi_fingers(roi):\n",
    "    img = roi.copy()\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    ###이진화\n",
    "    # 마스크 생성을 위해, 밝기 강조한 Lab으로 이미지 변환\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_Lab2BGR)\n",
    "    # 이미지 노이즈 제거\n",
    "    img = cv2.fastNlMeansDenoising(img, None, 5, 9, 15)\n",
    "\n",
    "    # 모폴로지\n",
    "    k2 = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, k2)\n",
    "\n",
    "    # Grayscale로 이미지 변환\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 이미지 평탄화\n",
    "    clahe = cv2.createCLAHE(clipLimit=5, tileGridSize=(70, 70))\n",
    "    dst1 = clahe.apply(img)\n",
    "\n",
    "    k2 = cv2.getStructuringElement(cv2.MORPH_RECT, (45, 45))\n",
    "    img = cv2.morphologyEx(dst1, cv2.MORPH_TOPHAT, k2)\n",
    "\n",
    "    # print(np.mean(img))\n",
    "    # print(np.mean(img)*1.18)\n",
    "\n",
    "    # 이진화\n",
    "    threshold = 0\n",
    "    if np.mean(img) > 12:\n",
    "        threshold = 7\n",
    "    elif 10.5 <= np.mean(img) <= 11.6:\n",
    "        threshold = 6.5\n",
    "    elif 10 <= np.mean(img) <= 10.4:\n",
    "        threshold = 6.0\n",
    "    elif 9.3 <= np.mean(img) <= 9.9:\n",
    "        threshold = 5.8\n",
    "    elif 8.3 <= np.mean(img) <= 9.2:\n",
    "        threshold = 5.6\n",
    "    elif 5.9 <= np.mean(img) <= 8.2:\n",
    "        threshold = 5.0\n",
    "    elif 3.8 <= np.mean(img) <= 5.8:\n",
    "        threshold = 4.0\n",
    "    elif np.mean(img) < 3.8:\n",
    "        threshold = np.mean(img)\n",
    "\n",
    "    # print(threshold)\n",
    "    ret, mask = cv2.threshold(img, threshold, 255, cv2.THRESH_BINARY)\n",
    "    # 컨투어\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(mask, contours, -1, (255, 255, 255), -1)\n",
    "\n",
    "    ###강조\n",
    "    img = roi.copy()\n",
    "\n",
    "    # 모폴로지\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, k)\n",
    "\n",
    "    # contrast\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if img.mean() <= 15:\n",
    "        low = img.mean() * 1.5\n",
    "        high = img.mean() * 1.6\n",
    "    elif img.mean() <= 20:\n",
    "        low = img.mean() * 1.5\n",
    "        high = img.mean() * 1.8\n",
    "    else:\n",
    "        low = img.mean() * 1.5\n",
    "        high = img.mean() * 2\n",
    "\n",
    "    img = contrast_roi(img, low, high)\n",
    "\n",
    "    # 컨투어\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(img, contours, -1, (255, 255, 255), -1)\n",
    "\n",
    "    # 마스크랑 비트 연산\n",
    "    img = cv2.bitwise_and(img, mask)\n",
    "\n",
    "    # 크기 표준화\n",
    "    img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    roi_height, roi_width = img.shape\n",
    "\n",
    "    for y in range(roi_height):\n",
    "        for x in range(roi_width):\n",
    "            if 0 <= y < roi_height * 0.5 and x > 220:\n",
    "                img[y][x] = 0\n",
    "            if roi_height * 0.5 <= y < roi_height * 0.70 and x > 243:\n",
    "                img[y][x] = 0\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def roi_finger_bone(img):\n",
    "    img = cv2.resize(img, (700, 928))\n",
    "    r_img_ = img.copy()\n",
    "    img_ = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    height, width = img_.shape\n",
    "    img_ = img_[0:(int)(height * 0.9), 0:(int)(width * 0.95)]\n",
    "    ret, img = cv2.threshold(img_, img.mean() * 0.99, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # 좌표 저장공간 설정(첫번째 공간에는 무게중심점, 두번째 공간에는 start점, 세번째에는 far점)\n",
    "    dots = [[], [], []]\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    max_cnt = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    mask = np.zeros(img.shape, dtype=np.uint8)\n",
    "\n",
    "    # 컨투어 구하고 구한 컨투어로 이미지 그리기\n",
    "    cv2.drawContours(mask, [max_cnt], -1, (255, 255, 255), -1)\n",
    "\n",
    "    # 이미지 팽창\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    mask = cv2.dilate(mask, k)\n",
    "\n",
    "    # 회전하기 위해서 가운데 손가락이 가장 길기때문에 가장 먼저 흰색을 나타내는 좌표를 찾아 낸다.\n",
    "    first_255_x_point = 0\n",
    "    first_255_y_point = 0\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    max_cnt = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # 무게중심점 구하기 일단\n",
    "    M = cv2.moments(max_cnt)\n",
    "    center = (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "\n",
    "    for y, x_r in enumerate(mask):\n",
    "        if 255 in x_r:\n",
    "            x_255_indexs = np.where(x_r == 255)[0]\n",
    "\n",
    "            x_255_mid_index = x_255_indexs[(int)(len(x_255_indexs) / 2)]\n",
    "            first_255_x_point = x_255_mid_index\n",
    "\n",
    "            first_255_y_point = y\n",
    "            break\n",
    "\n",
    "    # width 의 중간값의 x값과 가장 먼저 흰색을 나타내는 좌표의 x값을 비교한다.\n",
    "    # 그리고 center 값을 기준으로 회전한다.\n",
    "\n",
    "    half_h, half_w = center[1], center[0]\n",
    "    ry = center[1] - first_255_y_point\n",
    "    rx = abs(first_255_x_point - half_w)\n",
    "    radian = math.atan2(ry, rx)\n",
    "    degree = 90 - (radian * 180 / math.pi)\n",
    "    #print(\"회전각도 : \", degree)\n",
    "\n",
    "    if degree > 3:\n",
    "        if first_255_x_point < half_w:\n",
    "            mask = rotate_image(mask, 360 - degree)\n",
    "            r_img_ = rotate_image(img_, 360 - degree)\n",
    "        else:\n",
    "            mask = rotate_image(mask, degree)\n",
    "            r_img_ = rotate_image(img_, degree)\n",
    "\n",
    "            # 이미지 외부 컨투어 구하기\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    max_cnt = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # 무게중심점 구하기 일단\n",
    "    M = cv2.moments(max_cnt)\n",
    "    center = (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "\n",
    "    # cv2.circle(r_img_,center,0,[255,255,255],10)\n",
    "    dots[0].append(center)\n",
    "\n",
    "    # 볼록한 지점 구하기\n",
    "    hull1 = cv2.convexHull(max_cnt)\n",
    "    # cv2.drawContours(img_, [hull1], -1, (0,255,0),10)\n",
    "\n",
    "    # 새끼손가락 시작점 x좌표\n",
    "    little_finger_x = ()\n",
    "    little_finger_y = ()\n",
    "\n",
    "    min_little_finger_x = hull1[0][0][0]\n",
    "    max_little_finger_y = hull1[0][0][1]\n",
    "\n",
    "    for i in range(1, len(hull1)):\n",
    "        if min_little_finger_x > hull1[i][0][0] and hull1[i][0][0] > 0 and hull1[i][0][1] < center[1]:\n",
    "            min_little_finger_x = hull1[i][0][0]\n",
    "            max_little_finger_y = hull1[i][0][1]\n",
    "            little_finger_x, little_finger_y = hull1[i][0]\n",
    "\n",
    "    # 엄지손가락 시작점 좌표\n",
    "    thumb_x = ()\n",
    "    thumb_y = ()\n",
    "\n",
    "    max_thumb_x = hull1[0][0][0]\n",
    "    for i in range(0, len(hull1)):\n",
    "        if max_thumb_x < hull1[i][0][0] and hull1[i][0][1] < center[1] * 1.4 and hull1[i][0][1] > height * 0.3:\n",
    "            max_thumb_x = hull1[i][0][0]\n",
    "            thumb_x, thumb_y = hull1[i][0]\n",
    "\n",
    "            # 볼록한 지점 구하기\n",
    "    hull = cv2.convexHull(max_cnt, returnPoints=False)\n",
    "\n",
    "    # 오목한 지점 구하기\n",
    "    defects = cv2.convexityDefects(max_cnt, hull)\n",
    "\n",
    "    # 거리를 저장 할 수 있는 공간 생성\n",
    "    di = []\n",
    "\n",
    "    for index in range(defects.shape[0]):\n",
    "        # 시작점,끝점,far점,거리 할당\n",
    "        start_point, end_point, far_point, distance = defects[index, 0]\n",
    "\n",
    "        far = tuple(max_cnt[far_point][0])\n",
    "        start = tuple(max_cnt[start_point][0])\n",
    "        end = tuple(max_cnt[end_point][0])\n",
    "\n",
    "        # cv2.circle(r_img_,far,2,[255,255,255],10)\n",
    "        # cv2.circle(r_img_,start,2,[255,255,255],10)\n",
    "\n",
    "        # cv2.circle(r_img_,end,2,[255,255,255],10)\n",
    "        # 거리를 저장\n",
    "        di.append(distance)\n",
    "        dots[1].append(start)\n",
    "        dots[2].append(far)\n",
    "\n",
    "    # 더 쉽게 불러오기 위해서 far, start로 분리\n",
    "    far_pt = np.array(dots[2])\n",
    "    start_pt = np.array(dots[1])\n",
    "\n",
    "    far_xrange = []\n",
    "    far_yrange = []\n",
    "    far_miny = 1000\n",
    "    far_maxy = 0\n",
    "    start_miny = 1000\n",
    "    # 가장 오목하게 들어가 있는 부분을 찾기 위해서 sort(내림차순)\n",
    "    di = np.array(di)\n",
    "    s_di = np.sort(di)[::-1]\n",
    "    # 내림차순된 거리들을 6개만 뽑아내기 위해서 slice\n",
    "    for i in list(s_di[:6]):\n",
    "        index = np.where(di == i)[0]\n",
    "        # 6개의 좌표들 중에서 가장 최저의 y 값을 찾는다. (손목쪽 roi에 필요)\n",
    "        far_miny = min(far_miny, far_pt[index[0]][1])\n",
    "        # 6개의 좌표들 중에서 가장 최고의 y 값을 찾는다.\n",
    "        far_maxy = max(far_maxy, far_pt[index[0]][1])\n",
    "\n",
    "        # 가장 오목한 지점 6개의 좌표를 출력\n",
    "        # cv2.circle(r_img_,np.array(far_pt[index[0]]),2,[255,255,255],5)\n",
    "\n",
    "        # 좌표들이 x,y로 나눠져 있어서 쉽게 비교하기 위해서 x,y끼리 나눈다.\n",
    "        far_xrange.append(far_pt[index[0]][0])\n",
    "        far_yrange.append(far_pt[index[0]][1])\n",
    "\n",
    "    # far_xrange를 오름차순으로 정렬\n",
    "    sorted_far_xrange = np.sort(far_xrange)\n",
    "    sorted_far_yrange = np.sort(far_yrange)\n",
    "\n",
    "    carpus_start_point = ((int)(np.sort(far_xrange)[0]), (int)(center[1] * 1.05))\n",
    "\n",
    "    carpus_end_point_y = (int)(far_maxy * 1.09)\n",
    "    carpus_end_point_x = np.sort(far_xrange)[-2]\n",
    "    if carpus_end_point_x > center[0] * 1.4:\n",
    "        carpus_end_point_x = np.sort(far_xrange)[-2]\n",
    "    if carpus_end_point_y > height * 0.82:\n",
    "        carpus_end_point_y = height * 0.82\n",
    "    carpus_end_point = (carpus_end_point_x, int(carpus_end_point_y))\n",
    "\n",
    "    # 새끼손가락 endpoint x 좌표\n",
    "    little_finger_endpoint_x_list = []\n",
    "    for x, y in zip(far_xrange, far_yrange):\n",
    "        if y < int(center[1]):\n",
    "            little_finger_endpoint_x_list.append(x)\n",
    "\n",
    "    # 엄지손가락 endpoint\n",
    "    thumb_endpoint_list = []\n",
    "    for x, y in zip(far_xrange, far_yrange):\n",
    "        if y > int(center[1]) and x > int(center[0]):\n",
    "            thumb_endpoint_list.append([x, y])\n",
    "\n",
    "    thumb_endpoint = []\n",
    "    max_y = thumb_endpoint_list[0][1]\n",
    "    # print(thumb_endpoint_list[0][1])\n",
    "    if len(thumb_endpoint_list) == 1:\n",
    "        thumb_endpoint = thumb_endpoint_list\n",
    "    for i in range(1, len(thumb_endpoint_list)):\n",
    "        if max_y < thumb_endpoint_list[i][1]:\n",
    "            max_y = thumb_endpoint_list[i][1]\n",
    "            thumb_endpoint.append(thumb_endpoint_list[i])\n",
    "        else:\n",
    "            thumb_endpoint.append(thumb_endpoint_list[0])\n",
    "\n",
    "    # 손목뼈 부분 roi 를 하기 위해서는 가장 오목하게 들어가 있는 부분중에서 가장 최저 x값(xrange[0])과 center값의 y값을 시작점으로\n",
    "    # 끝점으로는 가장 오목하게 들어가 있는 부분들 중에서 가장 최고 x값(xrange[-1])과 오목하게 들어간 점중에서 가장 최고 y값을 준다.\n",
    "    # cv2.rectangle(r_img_,carpus_start_point,carpus_end_point,[255,255,255],5)\n",
    "    wrist_roi = r_img_[(int)(center[1] * 1.05):int(carpus_end_point_y),\n",
    "                (int)(np.sort(far_xrange)[0]):carpus_end_point_x]\n",
    "\n",
    "    #print(\"==================================================================\")\n",
    "    #print(\"손목 관절 roi 추출 시작좌표 : \", carpus_start_point)\n",
    "    #print(\"손목 관절 roi 추출 끝 좌표 : \", carpus_end_point)\n",
    "\n",
    "    # 손목뼈 위쪽에 있는 관절 4개를 추출하기 위해서는 오목하게 들어가 있는 부분중에서 가장 최저 x값(xrange[0])과 far_miny 값을 y값으로\n",
    "    # 끝점으로는 가장 오목하게 들어가 있는 부분들 중에서 가장 최고 x값(xrange[-1])과 center의 y값을 준다.\n",
    "\n",
    "    four_end_point_x = np.sort(far_xrange)[-1]\n",
    "    if four_end_point_x > center[0] * 1.4:\n",
    "        four_end_point_x = np.sort(far_xrange)[-2]\n",
    "\n",
    "    four_start_point_y = far_miny\n",
    "    if four_start_point_y < int(little_finger_y * 0.8) and four_start_point_y < int(thumb_y * 0.9):\n",
    "        four_start_point_y = int(center[1] * 0.7)\n",
    "\n",
    "    four_start_point = ((int)(np.sort(far_xrange)[0] * 0.85), four_start_point_y)\n",
    "    four_end_point = (four_end_point_x, (int)(center[1] * 1.05))\n",
    "\n",
    "    # cv2.rectangle(r_img_,four_start_point,four_end_point,[255,255,255],5)\n",
    "\n",
    "    middle_roi = r_img_[four_start_point_y:(int)(center[1] * 1.05),\n",
    "                 (int)(np.sort(far_xrange)[0] * 0.85):four_end_point_x]\n",
    "\n",
    "    #print(\"==================================================================\")\n",
    "    #print(\"가운데 4개 관절 roi 추출 시작좌표 : \", four_start_point)\n",
    "    #print(\"가운데 4개 관절 roi 추출 끝 좌표 : \", four_end_point)\n",
    "    # 가운데 손가락을 추출하기 위해서 start_pt의 x 좌표가 sorted_far_xrange 에서 3번째와 4번째 값 사이에 있어야 한다.\n",
    "    middle_index = np.where((start_pt[:, 0] <= (int)(sorted_far_xrange[3])) & (start_pt[:, 0] >= sorted_far_xrange[2]))[\n",
    "        0]\n",
    "    # 위에 조건식으로 나온 인덱스를 start_point에 대입하면 만족하는 좌표들이 여러개 나올것이다.\n",
    "    middle_points = start_pt[middle_index]\n",
    "\n",
    "    # 새끼손가락 ROI\n",
    "    little_finger_end_point_x = min(little_finger_endpoint_x_list)\n",
    "    if carpus_start_point[0] == little_finger_end_point_x:\n",
    "        little_finger_end_point_x = np.sort(little_finger_endpoint_x_list)[1]\n",
    "    if little_finger_end_point_x == sorted_far_xrange[2]:\n",
    "        little_finger_end_point_x = min(little_finger_endpoint_x_list)\n",
    "\n",
    "    little_finger_start_point = (int(little_finger_x * 0.5), int(little_finger_y * 0.8))\n",
    "    little_finger_end_point = (little_finger_end_point_x, (int)(center[1] * 1.05))\n",
    "    # cv2.rectangle(r_img_,little_finger_start_point, little_finger_end_point,[255,255,255],2)\n",
    "\n",
    "    little_finger_roi = r_img_[int(little_finger_y * 0.8):(int)(center[1] * 1.05),\n",
    "                        int(little_finger_x * 0.5):little_finger_end_point_x]\n",
    "    # cv2.imshow('little_finger_roi', little_finger_roi)\n",
    "    #print(\"==================================================================\")\n",
    "    #print(\"새끼손가락 roi 추출 시작좌표 : \", little_finger_start_point)\n",
    "    #print(\"새끼손가락 roi 추출 끝 좌표 : \", little_finger_end_point)\n",
    "\n",
    "    # 엄지손가락 ROI\n",
    "\n",
    "    if not thumb_x or not thumb_y:\n",
    "        thumb_x, thumb_y = 610, 250\n",
    "        thumb_end_point_x, thumb_end_point_y = 450, 619\n",
    "    else:\n",
    "        thumb_x, thumb_y = int(thumb_x * 1.02), int(thumb_y * 0.9)\n",
    "        thumb_end_point_x, thumb_end_point_y = int(thumb_endpoint[0][0] * 1.05), int(thumb_endpoint[0][1])\n",
    "\n",
    "    thumb_start_point = (thumb_x, thumb_y)\n",
    "    thumb_end_point = (thumb_end_point_x, int(thumb_end_point_y))\n",
    "\n",
    "    # cv2.rectangle(r_img_,thumb_start_point, thumb_end_point,[255,255,255],2)\n",
    "\n",
    "    thumb_roi = r_img_[thumb_y:thumb_end_point_y, thumb_end_point_x:thumb_x]\n",
    "    # cv2.imshow('thumb_roi', thumb_roi)\n",
    "    #print(\"==================================================================\")\n",
    "    #print(\"엄지손가락 roi 추출 시작좌표 : \", thumb_start_point)\n",
    "    #print(\"엄지손가락 roi 추출 끝 좌표 : \", thumb_end_point)\n",
    "\n",
    "    for point in middle_points:\n",
    "        # 가운데 손가락 사이에 있는 좌표들 중에서 최저 y 값을 찾는다.\n",
    "        start_miny = min(start_miny, point[1])\n",
    "\n",
    "    start_maxy = max(far_yrange[np.where(far_xrange == sorted_far_xrange[3])[0][0]],\n",
    "                     far_yrange[np.where(far_xrange == sorted_far_xrange[2])[0][0]])\n",
    "    if start_maxy > center[1]:\n",
    "        start_maxy = center[1] * 0.8\n",
    "    # 시작 좌표로는 x값으로 sorted_far_xrange 에서 3번째와 y 값으로는 최저y 값을 주고\n",
    "    # 마지막 좌표로는 x값으로 sorted_far_xrange 에서 4번째와 y값으로는 3번째 와 4번째 좌표의 최고 y 값을 준다.\n",
    "    middle_finger_start_point = (sorted_far_xrange[2], start_miny)\n",
    "    middle_finger_end_point = (sorted_far_xrange[3], int(start_maxy * 1.1))\n",
    "\n",
    "    # cv2.rectangle(r_img_,middle_finger_start_point,middle_finger_end_point,[255,255,255],5)\n",
    "\n",
    "    middle_finger_roi = r_img_[start_miny:int(start_maxy * 1.1), sorted_far_xrange[2]: sorted_far_xrange[3]]\n",
    "    # cv2.imshow('middle_finger_roi', middle_finger_roi)\n",
    "    #print(\"==================================================================\")\n",
    "    #print(\"가운데 손가락 roi 추출 시작좌표 : \", middle_finger_start_point)\n",
    "    #print(\"가운데 손가락 roi 추출 끝 좌표 : \", middle_finger_end_point)\n",
    "\n",
    "    rois = np.array([wrist_roi, middle_roi, little_finger_roi, thumb_roi, middle_finger_roi])\n",
    "    # cv2.imshow('r_img_',r_img_)\n",
    "    return rois\n",
    "\n",
    "def img_roi(img):\n",
    "    rois = roi_finger_bone(img)\n",
    "    for j in range(0, len(rois)):\n",
    "        if j == 0:\n",
    "            wrist_roi = filter_roi_carpal_and_joint(rois[j])\n",
    "    return wrist_roi\n",
    "\n",
    "def print_roi(img):\n",
    "    rois = roi_finger_bone(img)\n",
    "    try:\n",
    "        for j in range(0, len(rois)):\n",
    "            if j == 0:\n",
    "                wrist_roi = filter_roi_carpal_and_joint(rois[j])\n",
    "                if wrist_roi.ndim == 3:\n",
    "                    wrist_roi = wrist_roi[:, :, 0]\n",
    "            elif j == 1:\n",
    "                middle_roi = filter_roi_carpal_and_joint(rois[j])\n",
    "                if middle_roi.ndim == 3:\n",
    "                    middle_roi = middle_roi[:, :, 0]\n",
    "            elif j == 2:\n",
    "                little_finger_roi = filter_roi_fingers(rois[j])\n",
    "                if little_finger_roi.ndim == 3:\n",
    "                    little_finger_roi = little_finger_roi[:, :, 0]\n",
    "            elif j == 3:\n",
    "                thumb_roi = filter_roi_fingers(rois[j])\n",
    "                if thumb_roi.ndim == 3:\n",
    "                    thumb_roi = thumb_roi[:, :, 0]\n",
    "            else:\n",
    "                middle_finger_roi = filter_roi_fingers(rois[j])\n",
    "                if middle_finger_roi.ndim == 3:\n",
    "                    middle_finger_roi = middle_finger_roi[:, :, 0]\n",
    "        roi_ = np.array([wrist_roi, middle_roi, little_finger_roi, thumb_roi, middle_finger_roi])\n",
    "        return roi_\n",
    "    except:\n",
    "        print(\"에러처리\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d9a7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c60882a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 9, in <module>\n",
      "    from tensorflow.keras.models import load_model\n",
      "ModuleNotFoundError: No module named 'tensorflow'\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66529d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load main.py\n",
    "from PyQt5 import QtGui, QtCore, QtWidgets, uic\n",
    "from PyQt5.QtGui import *\n",
    "from PyQt5.QtWidgets import *\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import img_processing\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from PyQt5.QtGui import QPixmap\n",
    "\n",
    "MainUI = \"./main_test.ui\"\n",
    "app = QApplication(sys.argv)\n",
    "\n",
    "class MainWindow(QMainWindow):\n",
    "    def __init__(self) -> object:\n",
    "        super().__init__()\n",
    "        uic.loadUi(MainUI, self)\n",
    "\n",
    "        #초기값 설정\n",
    "        self.image = None #원본 이미지\n",
    "        self.roi = None #ROI 이미지\n",
    "        self.output = None #골연령 예측 결과\n",
    "\n",
    "\n",
    "        self.gender = np.array([0]) #성별. 화면에서 Male 체크를 기본으로 함. 입력변수 Female [0], Male [1]\n",
    "        self.model = load_model('./models/checkpoint-50-epochs-16-batchs.h5')\n",
    "\n",
    "        #초기 화면에서 sample 이미지 보여주기\n",
    "        #QPixmap이란, PyQt에서 이미지를 보여줄 때 사용하는 객체로 위에 사진에 있는 포맷들을 지원하는 객체\n",
    "        self.qPixmapFile_origin = QPixmap()\n",
    "        #샘플이미지 설정, 경로설정\n",
    "        self.qPixmapFile_origin.load(\"./image/sample_origin.png\")\n",
    "        #사이즈 설정, 사이즈는 PYQT디자이너에서 정한 사이즈 내에서 새로 정할 수 잇음.\n",
    "        self.qPixmapFile_origin = self.qPixmapFile_origin.scaled(450, 500)\n",
    "        # 위에서 설정한 QPixmap을 표시하는 메서드, 마치 마지막 마침표와 같아 없어면 포시 X\n",
    "        self.label_origin.setPixmap(self.qPixmapFile_origin)\n",
    "\n",
    "\n",
    "\n",
    "        #버튼 클릭시 함수 연결\n",
    "        self.pushButton_upload.clicked.connect(self.openFileNameDialog) #Upload\n",
    "        self.radioButton_male.clicked.connect(self.gender_checked) #Male\n",
    "        self.radioButton_female.clicked.connect(self.gender_checked) #Female\n",
    "\n",
    "\n",
    "\n",
    "    def openFileNameDialog(self):  # opencv로 이미지 불러와서 qimage resize로 사이즈 줄인 후 label에 보여주기.\n",
    "        fileName, _ = QFileDialog.getOpenFileName(self, \"파일 선택\", \"\",\n",
    "                                                  \"Image files (*.jpg *.gif *.png)\")\n",
    "\n",
    "        if fileName:\n",
    "            self.setWindowTitle(fileName)\n",
    "            self.fileName = fileName\n",
    "            self.image = cv2.imdecode(np.fromfile(fileName, np.uint8), cv2.IMREAD_COLOR)  # cv2.imread()\n",
    "\n",
    "            self.label_origin_show(self.image)\n",
    "            self.wrist = img_processing.img_roi(self.image)\n",
    "            self.roi = img_processing.print_roi(self.image)\n",
    "            self.label_roi_show(self.wrist)\n",
    "\n",
    "            self.output = self.bone_age_pred(self.roi)\n",
    "            self.label_prediction_show(self.output)\n",
    "\n",
    "    #좌측 화면(label_origin)에 이미지 보여주는 함수\n",
    "    def label_origin_show(self, image):\n",
    "        self.img = QtGui.QImage(image.data, image.shape[1], image.shape[0], image.shape[1]*3,\n",
    "                                    QtGui.QImage.Format_RGB888).rgbSwapped()\n",
    "        self.img = QtGui.QImage(self.img).scaled(450, 500, QtCore.Qt.KeepAspectRatio)  # GUI에 보여주기 위한 용도로 사진 줄이기\n",
    "        self.label_origin.setPixmap(QtGui.QPixmap.fromImage(self.img))\n",
    "\n",
    "\n",
    "    #아래 좌측 화면(label_roi)에 이미지 보여주는 함수\n",
    "    def label_roi_show(self, image):\n",
    "        #print(image.shape)\n",
    "        self.img = QtGui.QImage(image.data, image.shape[1], image.shape[0], image.shape[1] * 3,\n",
    "                                QtGui.QImage.Format_RGB888).rgbSwapped()\n",
    "        self.img = QtGui.QImage(self.img).scaled(180, 180, QtCore.Qt.KeepAspectRatio)\n",
    "        self.label_roi.setPixmap(QtGui.QPixmap.fromImage(self.img))\n",
    "\n",
    "\n",
    "\n",
    "    #Male, Female 체크시 성별 변경\n",
    "    def gender_checked(self):\n",
    "        if self.radioButton_male.isChecked():\n",
    "            self.gender = np.array([1])\n",
    "        if self.radioButton_female.isChecked():\n",
    "            self.gender = np.array([0])\n",
    "\n",
    "        if self.wrist is not None: #이미지 업로드 후 성별 변경시 골연령 다시 예측\n",
    "            if type(self.gender) == type(self.roi): #이미지 업로드 후 roi가 array 타입인 경우, 성별 체크시 골연령 다시 예측\n",
    "                self.output = self.bone_age_pred(self.roi)\n",
    "                self.label_prediction_show(self.output)\n",
    "\n",
    "    #골연령 예측 모형\n",
    "    def bone_age_pred(self, roi): #gender, roi 모두 array 타입\n",
    "        input = roi\n",
    "        model = load_model('./models/tjnet_model.h5')\n",
    "        prediction = self.model.predict(input.reshape(-1, 256, 256, 5))\n",
    "        output = str(round(prediction[0][0], 1))\n",
    "        return output\n",
    "\n",
    "    #골연령 예측 결과 보여주기(Main)\n",
    "    def label_prediction_show(self, output):\n",
    "        self.label_prediction.setText(\"Bone-Age : \" + output + \" years\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_window = MainWindow()\n",
    "    main_window.show()\n",
    "    app.exec_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e040883c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbd4fa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"tjnet_model.py\", line 11, in <module>\n",
      "    import tensorflow as tf\n",
      "ModuleNotFoundError: No module named 'tensorflow'\n"
     ]
    }
   ],
   "source": [
    "!python tjnet_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c9798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tjnet_model.py\n",
    "\"\"\"tjnet_model.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/18OMxML2I2nSKR-J8Zifw8IXiemsNM_mw\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import torch\n",
    "\n",
    "from keras.models import load_model\n",
    "model = load_model('/content/drive/MyDrive/tjnet_model.h5')\n",
    "\n",
    "bones = np.load('/content/drive/MyDrive/xdata.npy',allow_pickle=True)\n",
    "age = np.load('/content/drive/MyDrive/ydata.npy',allow_pickle=True)\n",
    "\n",
    "#separable 합성곱 함수\n",
    "def separable_conv(x,inchannel,outchannel):\n",
    "  x = keras.layers.Conv2D(inchannel,(3,3),strides=1,padding=\"same\")(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Conv2D(outchannel,(1,1),strides=1,padding=\"same\")(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  return x\n",
    "\n",
    "#model middle_flow 함수\n",
    "def middle_flow(input_x):\n",
    "  #encoder\n",
    "  x = keras.layers.MaxPool2D((2,2),padding=\"same\")(input_x)\n",
    "  x = resiual_units(x)\n",
    "  x = keras.layers.MaxPool2D((2,2),padding=\"same\")(x)\n",
    "  x = resiual_units(x)\n",
    "  x = keras.layers.MaxPool2D((2,2),padding=\"same\")(x)\n",
    "  x = resiual_units(x)\n",
    "  \n",
    "  \n",
    "\n",
    "  #decoder\n",
    "  x = resiual_units(x)\n",
    "  x = keras.layers.UpSampling2D((2,2),interpolation='bilinear')(x)\n",
    "  x = resiual_units(x)\n",
    "  x = keras.layers.UpSampling2D((2,2),interpolation='bilinear')(x)\n",
    "  x = resiual_units(x)\n",
    "  x = keras.layers.UpSampling2D((2,2),interpolation='bilinear')(x)\n",
    "  \n",
    "  x = separable_conv(x,x.shape[-1],512)\n",
    "  x = separable_conv(x,x.shape[-1],512) \n",
    "  \n",
    "  #sigmoid \n",
    "  x = keras.activations.sigmoid(x)\n",
    "  x = keras.layers.Multiply()([input_x,x])\n",
    "  x = keras.layers.Add()([input_x,x])\n",
    "\n",
    "  x = resiual_units(x)\n",
    "\n",
    "  return x\n",
    "\n",
    "#resiual_units 함수 \n",
    "def resiual_units(input_x):\n",
    "  x = keras.layers.ReLU()(input_x)\n",
    "  x = separable_conv(x,x.shape[-1],128)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "  x = keras.layers.ReLU()(x)\n",
    "  x = separable_conv(x,x.shape[-1],256)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "  x = keras.layers.ReLU()(x)\n",
    "  x = separable_conv(x,x.shape[-1],512)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  \n",
    "  input_x = keras.layers.Add()([x,input_x])\n",
    "\n",
    "  return input_x\n",
    "\n",
    "#골연령 측정 모델\n",
    "#entry flow model\n",
    "input = keras.Input(shape=(256,256,5))\n",
    "x = keras.layers.Conv2D(32,(3,3),strides=2)(input)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "\n",
    "x = keras.layers.Conv2D(64,(3,3),strides=1)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "#첫번째\n",
    "x1 = keras.layers.Conv2D(128,(1,1),strides=2)(x) \n",
    "x1 = keras.layers.BatchNormalization()(x1)\n",
    "\n",
    "x = separable_conv(x,x.shape[-1],128)\n",
    "x = keras.layers.ReLU()(x)\n",
    "\n",
    "x = separable_conv(x,x.shape[-1],128)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.MaxPool2D((2,2),2,padding=\"same\")(x)\n",
    "\n",
    "x = keras.layers.Add()([x,x1])\n",
    "#2번째\n",
    "x1 = keras.layers.Conv2D(512,(1,1),strides=2)(x)\n",
    "x1 = keras.layers.BatchNormalization()(x1)\n",
    "\n",
    "x = separable_conv(x,x.shape[-1],512)\n",
    "x = keras.layers.ReLU()(x)\n",
    "\n",
    "x = separable_conv(x,x.shape[-1],512)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.MaxPool2D((2,2),2,padding=\"same\")(x)\n",
    "\n",
    "x = keras.layers.Add()([x,x1])\n",
    "\n",
    "\n",
    "#middle flow model\n",
    "x = middle_flow(x)\n",
    "\n",
    "\n",
    "#exit flow model\n",
    "x1 = keras.layers.Conv2D(1024,(1,1),strides=2)(x)\n",
    "\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = separable_conv(x,x.shape[-1],728)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = separable_conv(x,x.shape[-1],1024)\n",
    "x = keras.layers.MaxPool2D((2,2),2,padding=\"same\")(x)\n",
    "\n",
    "x = keras.layers.Add()([x,x1])\n",
    "\n",
    "\n",
    "x = separable_conv(x,x.shape[-1],1536)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = separable_conv(x,x.shape[-1],2048)\n",
    "x = keras.layers.ReLU()(x)\n",
    "\n",
    "x = keras.layers.GlobalAvgPool2D()(x)\n",
    "\n",
    "x = keras.layers.Dense(1000,activation='relu')(x)\n",
    "x = keras.layers.Dense(256,activation='relu')(x)\n",
    "x = keras.layers.Dense(1)(x)\n",
    "\n",
    "model = keras.models.Model(input,x)\n",
    "model.compile(optimizer='adam',loss='mae',metrics=['mae','mse'])\n",
    "\n",
    "model.save('./tjnet_model.h5')\n",
    "\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "import pydot\n",
    "import graphviz\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True, show_layer_names=True, rankdir='TB',expand_nested=False, dpi=60, subgraph=False).create(prog='dot',format='svg'))\n",
    "\n",
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "# %tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "bones = np.load('/content/drive/MyDrive/xdata.npy',allow_pickle=True)\n",
    "age = np.load('/content/drive/MyDrive/ydata.npy',allow_pickle=True)\n",
    "X_data = bones[:,1]\n",
    "y = age\n",
    "\n",
    "\n",
    "filename = 'checkpoint-50-epochs-16-batchs.h5'\n",
    "checkpoint = ModelCheckpoint(filename,mointor='val_loss',verbose=1,save_best_only=True,mode='auto')\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "tmp = np.zeros((256,256))\n",
    "for _,x in enumerate(X_data):\n",
    "  if _ == 0:\n",
    "    tmp = x\n",
    "    tmp = tmp.reshape(256,256,5)\n",
    "    print(tmp)\n",
    "  else:\n",
    "    tmp = np.concatenate([tmp,x.reshape(256,256,5)])\n",
    "    \n",
    "X_data = tmp\n",
    "\n",
    "np.set_printoptions(formatter={'float_kind': lambda x: \"{0:0.1f}\".format(x)})\n",
    "y = y.astype(np.float)\n",
    "\n",
    "train_x,test_x,train_y,test_y = train_test_split(X_data.reshape(1200,256,256,-1),y,random_state=42,test_size=0.2)\n",
    "train_x,val_x,train_y,val_y = train_test_split(train_x,train_y,random_state=42,test_size=0.2)\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "  model.fit(train_x,train_y,batch_size=16,epochs=150,callbacks=checkpoint,validation_data=(val_x,val_y))\n",
    "\n",
    "prediction = model.predict(bones[400,1].reshape(-1,256,256,5))\n",
    "\n",
    "output = round(prediction[0][0], 1)\n",
    "print(output)\n",
    "\n",
    "y[400]\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21939249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
